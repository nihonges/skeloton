{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import main\n",
    "from daaloader import SkeletonPositions\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "# from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_points_2d_path = '/home/hussam/Documents/KIT/SS 2022/CV Praktikum/Dataset/Test Dataset/daa_pose3d_test/keypoints_2d/vp11/run1_2018-05-24-13-44-01.ids_1.manual.csv'\n",
    "key_points_3d_path = '/home/hussam/Documents/KIT/SS 2022/CV Praktikum/Dataset/Test Dataset/daa_pose3d_test/keypoints_3d/vp11/run1_2018-05-24-13-44-01.ids_1.triangulated.3d.csv'\n",
    "images_root_path = '/home/hussam/Documents/KIT/SS 2022/CV Praktikum/Dataset/Test Dataset/daa_pose3d_test/gt_images/vp11/run1_2018-05-24-13-44-01.ids_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Options:\n",
    "    action= 'All'\n",
    "    ckpt= ''\n",
    "    data_dir= 'data/'\n",
    "    dropout= 0.5\n",
    "    epochs= 10\n",
    "    exp= 'example'\n",
    "    is_train= True\n",
    "    job= 8\n",
    "    linear_size= 1024\n",
    "    load= ''\n",
    "    lr= 0.001\n",
    "    lr_decay= 100000\n",
    "    lr_gamma= 0.96\n",
    "    max_norm= True\n",
    "    num_stage= 2\n",
    "    procrustes= False\n",
    "    resume= False\n",
    "    test= False\n",
    "    test_batch= 64\n",
    "    train_batch= 64\n",
    "    use_hg= False\n",
    "opt = Options()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, key_points_2d, key_points_3d = sample['image'], sample['key_points_2d'], sample['key_points_3d']\n",
    "\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C x H x W\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        return {'image': torch.from_numpy(image),\n",
    "                'key_points_2d': torch.from_numpy(key_points_2d),\n",
    "                'key_points_3d': torch.from_numpy(key_points_3d)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_dataset = SkeletonPositions(key_points_2d_path,\n",
    "                                        key_points_3d_path,\n",
    "                                        images_root_path,\n",
    "                                        transform=transforms.Compose([\n",
    "                                               ToTensor(),\n",
    "                                           ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(transformed_dataset))\n",
    "test_size = len(transformed_dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(transformed_dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> creating model\n",
      ">>> total params: 4.29M\n",
      ">>> loading data\n",
      ">>> data loaded !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hussam/anaconda3/envs/baseline-pytorch-env/lib/python3.9/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================\n",
      ">>> epoch: 1 | lr: 0.00100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hussam/Documents/KIT/SS 2022/CV Praktikum/Approaches/daa_baseline/main.py:202: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  nn.utils.clip_grad_norm(model.parameters(), max_norm=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> error: 7.661562204945321 <<<\n",
      "==========================\n",
      ">>> epoch: 2 | lr: 0.00100\n",
      ">>> error: 3.4824130596483456 <<<\n",
      "==========================\n",
      ">>> epoch: 3 | lr: 0.00100\n",
      ">>> error: 2.080013021571087 <<<\n",
      "==========================\n",
      ">>> epoch: 4 | lr: 0.00100\n",
      ">>> error: 1.3829816505860757 <<<\n",
      "==========================\n",
      ">>> epoch: 5 | lr: 0.00100\n",
      ">>> error: 1.0260053791799675 <<<\n",
      "==========================\n",
      ">>> epoch: 6 | lr: 0.00100\n",
      ">>> error: 0.9053298483155302 <<<\n",
      "==========================\n",
      ">>> epoch: 7 | lr: 0.00100\n",
      ">>> error: 0.7925499989285919 <<<\n",
      "==========================\n",
      ">>> epoch: 8 | lr: 0.00100\n",
      ">>> error: 0.8085162071328537 <<<\n",
      "==========================\n",
      ">>> epoch: 9 | lr: 0.00100\n",
      ">>> error: 0.7449081795080108 <<<\n",
      "==========================\n",
      ">>> epoch: 10 | lr: 0.00100\n",
      ">>> error: 0.7395996664121163 <<<\n"
     ]
    }
   ],
   "source": [
    "main(opt, train_dataset, test_dataset)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "47827039a30f3f0932c4b9de0a3411a30547843e7e6374fdd12a444793dc70d4"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('baseline-pytorch-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
